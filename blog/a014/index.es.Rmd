---
title: Supuestos estadísticos
author: David Vanegas
date: '2021-11-02'
image: https://i.ibb.co/sF7Xfgq/ES.png
slug: []
categories:
  - R
  - RStudio
tags:
  - Análisis
  - Datos
  - Distribución
  - Normal
  - P valor
  - Parámetros
---

Otro de los aspectos que permite hacer la inferencia es determinar si existe o no asociación entre diferentes variables, es decir, de unas hipótesis cuya validez debemos confirmar o rechazar. 

# Contenido del post

- [Introducción](#1)
- [Normalidad](#2)
    - [Histograma y/o gráfico de densidad](#3)
    - [Gráfico de cuantiles teóricos](#4)
    - [Homocedasticidad](#5)
- [Conclusión](#6)
- [Bibliografía](#7)
- [Más información](#8)

<center>
![](https://i.ibb.co/bv4rMJs/dance.gif){width=350}
</center><br>

# Introducción 
<a name="1"></a>

Para llevar a cabo esta comprobación aplicamos unas pruebas estadísticas o tests, que permiten contrastar la veracidad o falsedad de las hipótesis enunciadas desde el punto de vista estadístico, si no recuerdas este tema, te invitamos a que leas nuestro pasado [Post](https://rbiologos.com/blog/a013/) Este tipo de pruebas se clasifican en pruebas paramétricas y pruebas no paramétricas.

En este nuevo post hablaremos de los test requeridos para considerar si nuestros datos se pueden manejar bajo las pruebas paramétricas o las no paramétricas, como supuestos de ***normalidad*** y ***homocedasticidad***. Cabe recordar que las pruebas _paramétricas_ ***exigen*** ciertos requisitos previos para su aplicación, donde su incumplimiento conlleva la necesidad de recurrir a pruebas estadísticas _no paramétricas_.

- Variable de estudio: tiene que ser numérica. Esto es, la variable dependiente debe estar medida en una escala que sea, por lo menos, de intervalo. 

- Normalidad: El análisis y observaciones que se obtienen de las muestras deben considerarse normales. 

- Homocedasticidad: Las varianzas de la variable dependiente en los grupos que se comparan deben ser aproximadamente iguales, es decir, que sean homogéneas,

- Errores: Los errores que se presenten deben de ser independientes. Esto solo sucede cuando los sujetos son asignados de forma aleatoria y se distribuyen de forma normal dentro del grupo.

- n muestreal: La n es el tamaño de la población. En este caso, el tamaño de la población de la muestra no puede ser inferior a 30, y será mejor cuanto más se acerque a la n de toda la población.

!Bien!

Entonces empecemos a aprender a como calcular cada uno de los requisitos para determinar si podemos hacer un estudio paramétrico o no

<center>
![](https://i.ibb.co/wCKxW7J/face.gif){width=350}
</center><br>

# Normalidad 
<a name="2"></a>

La lógica de la prueba se basa en las desviaciones que presentan las estadísticas de orden de la muestra respecto a los valores esperados de los estadísticos de orden de la normal estándar.

Para estudiar si una muestra aleatoria proviene de una población con distribución normal se disponen de tres herramientas que se listan a continuación.

- Histograma y/o densidad.
- Gráfico de cuantiles teóricos (QQplot).
- Pruebas de hipótesis.

Al evaluar visualmente la simetría de la distribución de los datos a partir de un gráfico de histograma y/o densidad, si observamos que este no cumple la simetría (sesgo a uno de los lados) o si se observa una distribución con más de una moda, eso sería indicio de que la muestra no proviene de una población normal. Por otra parte, si se observa simetría en los datos, esto ***NO*** garantiza que la muestra aleatoria proviene de una población normal y se hace necesario recurrir a otras herramientas específicas para estudiar normalidad como lo son los gráficos ***QQplot*** y pruebas de hipótesis.

<center>
![](https://i.ibb.co/3NK5WcB/faces.gif){width=350}
</center><br>

A continuación profundizaremos un poco sobre el uso de cada de las tres herramientas anteriormente nombradas para estudiar la normalidad.

## Histograma y/o gráfico de densidad 
<a name="3"></a>

Consiste en representar los datos mediante un histograma (Fig. 1) y/o gráfico de densidad (Fig. 2), superponer la curva de una distribución normal con la misma media y desviación estándar que muestran los datos.

Para realizar este ejemplo vamos a utilizar la base de datos <res>iris</res>, base que da las medidas en centímetros de las variables longitud y ancho del sépalo, y largo y ancho del pétalo, respectivamente, para 50 flores de cada una de las 3 especies de iris, con el fin de mostrar los alcances de este tipo de gráfica (Fig. 1) en la prueba

```{r out.width="100%"}
## Cargamos el paquete ggplot2
library(ggplot2)

## Calculamos la media y desviación estándar para la longitud del sépalo
distmean <- mean(iris$Sepal.Length)
distsd <- sd(iris$Sepal.Length)

## Y graficamos
ggplot(data = iris, aes(x = Sepal.Length)) +
   geom_histogram(aes(y = ..density.., fill = ..count.., color=..count..),
                  alpha = 0.7, binwidth = 0.2) +
  stat_function(fun = dnorm, colour = "black", size=2,
                args = list(mean = distmean, sd = distsd))+
  
  xlab("Distancia") + 
  ylab("Densidad")+
  theme(axis.title.y = element_text(size = 18),
        axis.title.x = element_text(size = 18),
        axis.text.y = element_text(size = 16),
        axis.text.x = element_text(size = 14))+
  theme(panel.border = element_blank(), 
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(), 
        axis.line = element_line(colour = "black", size = 1),
        panel.background = element_blank())+
  theme(legend.key = element_blank())+
  labs(colour = "Cantidad", fill = "Cantidad")
```
Fig. 1. Histograma y Curva normal teórica de la longitud del sépalo de las flores del género _Iris_

- ***Gráfica de densidad***

```{r out.width="100%"}
plot(density(iris$Sepal.Length), main = 'Density Plot of Sepal Length', xlab = ' Sepal Length')
```

Fig. 2. Histograma y Curva normal teórica de la longitud del sépalo de las flores del género _Iris_

Como muestran la gráficas, no queda claro el cumplimiento de la normalidad. Visualmente, la variable sepal lenght ***NO*** parece distribuida normalmente. En el gráfico de densidad se puede apreciar que tiene una parte superior plana con sesgo positivo. Esto es bastante común, por lo que el uso de todas las herramientas es fundamental para no caer en malas desiciones.

## Gráfico de cuantiles teóricos (qqplot) 
<a name="4"></a>

Consiste en comparar los cuantiles de la distribución observada con los cuantiles teóricos de una distribución normal con la misma media y desviación estándar que los datos. Cuanto más se aproximen los datos a una normal, más alineados están los puntos entorno a la recta. Este gráfico (Fig. 3) lo realizamos con la función <res>qqnorm()</res> y la recta de normalidad con <res>qqline()</res>.

```{r out.width="100%"}
qqnorm(iris$Sepal.Length, pch = 1, frame = FALSE, 
       main = "Gráfico Q-Q", 
       xlab = "Cuantiles teóricos", 
       ylab = "Quantiles de la muestra")
qqline(iris$Sepal.Length, col = "steelblue", lwd = 2)
```

Fig. 3. Gráfico de cuantiles teóricos con el la función _qqnorm_ de la longitud del sépalo de la base de datos _iris_

Otra forma de ver el comportamiento de nuestros datos es con el paquete <res>car</res>, el cuál nos mostrará de manera más óptima dicho comportamiento (Fig. 4) y su función <res>qqPlot()</res>

```{r out.width="100%", message=FALSE}
## El paquete "car", tiene como dependencia "carData"
library(car)

qqPlot(iris$Sepal.Length, pch = 16, col = c("black"), 
       col.lines = "blue", cex = 1,
       main = "Gráfica Q-Q", id = F )
```

Fig. 4. Gráfico de cuantiles teóricos con el la función _qqPlot_ de la longitud del sépalo de la base de datos _iris_

De acuerdo al comportamiento en el ***gráfico Q-Q***, podemos indagar que nuestros datos si parecen cierta distribución normal, observemos que los puntos parecen caer sobre una línea recta, sin embargo, como bien habíamos dicho anteriormente, es mejor realizar todos los pasos para no cometer algún error de apreciación.

- ***Pruebas de hipótesis***

Para poder asumir y contrastar los valores de las diferentes pruebas de hipótesis que veremos a continuación, es necesario tener bajo consideración el Test de hipótesis, el cual formularemos con un nivel de significancia de <res>α = 0.05</res> de la siguiente manera

```
Hipótesis nula (H0): Los datos siguen una distribución normal

Hipótesis alternativa (Ha): Los datos no siguen una distribución normal
```

Bajo la siguiente decisión: si el valor p es menor al valor α (p < α), la prueba estadística es significativa, no existiría normalidad en los datos.

Los paquetes que utilizaremos para realizar las diferentes pruebas son <res>nortest</res>, <res>normtest</res>

Para realizar los test de Normalidad de los datos, existen varias pruebas que podremos trabajar. Estas difieren entre ellas por lo métodos utilizados y/o cantidad de datos, así que siempre es mejor profundizar en los métodos que estamos utilizando para tener pleno conocimiento de lo que andamos haciendo.

A continuación veremos algunas de ellas

<center>
![](https://i.ibb.co/qJ04XPJ/Decisive.gif){width=350}
</center><br>

- ***Prueba de Anderson-Darling***

Es una prueba ***no paramétrica*** sobre los datos de una muestra que provienen de una distribución específica. Principalmente se basa en la distancia de la distribución hipotética F, y la función de la distribución empírica Fn, donde n es el número de elementos en la muestra.

> El número de muestra debe de ser mayor a 7 y permite missing values.

```{r}
## Paquete "nortest"
library(nortest)

## Fijamos la base de datos para utilizarla
attach(iris)

ad.test(Sepal.Length)
```

Así, nuestro p valor es igual a ***0.02251***, con lo que podríamos concluir que nuestros datos NO siguen una distribución normal

- ***Prueba de Cramer-Von Mises***

El Criterio de Cramer Von Mises, utiliza como criterio la distancia mínima de la función de distribución acumulada F en comparación con la función de distribución empírica Fn.

Es útil para pequeñas muestras y usa los momentos como criterio y es una alternativa a la prueba de Kolmogorov-Smirnov.

```{r}
## Paquete "nortest"

## Crearemos una pequeña base
Sepal.Length2 <- Sepal.Length[1:10]

cvm.test(Sepal.Length2)
```
Como nuestro p valor es igual a ***0.7033*** y por consiguiente mayor a ***0.05*** con lo que podríamos concluir que nuestros datos siguen una distribución normal

- ***Prueba de Lilliefors (Kolmogorov-Smirnov)***

Utiliza la diferencia máxima absoluta entre la función de distribución acumulada empírica y la hipotética

Aunque el estadístico de prueba obtenido de lillie.text(x) es el mismo que el obtenido de ks(x,"pnorm",mean(x),sd(x)), no es correcto usar el p-value de este último para la hipótesis compuesta de normalidad (media y varianza desconocidas), ya que la distribución del estadístico de prueba es diferente cuando se estiman los parámetros.

> Se aplica más ampliamente cuando la muestra es grande.

```{r}
## Paquete "nortest"

lillie.test(Sepal.Length)
```
Bajo este test nuestro p valor es igual a ***0.005788***, por lo que podríamos concluir que nuestros datos NO siguen una distribución normal

- ***Prueba de Pearson chi-square***

Compara la distribución observada de los datos con una distribución esperada. La prueba de χ2 de Pearson generalmente no se recomienda para probar en la hipótesis compuesta de normalidad debido a sus propiedades de potencia son inferiores en comparación con otras pruebas.

> Basada en una distribución χ2, que corresponde a una prueba de bondad de ajuste.

```{r}
## Paquete "nortest"

pearson.test(Sepal.Length)
```

El resultado de nuestro p valor en este tipo es igual a ***0.1352***, con lo que podríamos concluir que nuestros datos siguen una distribución normal

- ***Prueba de Shapiro-Francia***

La prueba de Shapiro-Francia es simplemente la correlación al cuadrado entre los valores de la muestra ordenados y los cuantiles esperados (aproximación) de la distribución normal estándar

> Simplificación de la prueba Shapiro-Wilk y este tipo de prueba funciona bien, también el número de datos debe estar entre 5 y 5000.

```{r}
## Paquete "nortest"

sf.test(Sepal.Length)
```

Así, nuestro p valor es igual a ***0.02621***, con lo que podríamos concluir que nuestros datos NO siguen una distribución normal

- ***Prueba de Frosini***

La prueba de Frosini para la normalidad se basa en el siguiente estadístico:

<center>
![](https://i.ibb.co/zGmDXCf/Frosini.jpg){width=200}
</center><br>

```{r}
## Paquete "normtest"
library(normtest)

frosini.norm.test(Sepal.Length, nrepl=2000)
```
El resultado de nuestro p valor es mayor a 0.05, con lo que podríamos concluir que nuestros datos siguen una distribución normal

- ***Prueba de Geary***

La prueba de Geary se basa en el siguiente estadístico

<center>
![](https://i.ibb.co/LrQ1C3J/Geray.jpg){width=200}
</center><br>

> Usa los valores acumulados muestrales, sus medias y desviaciones estándar

```{r}
## Paquete "normtest"
geary.norm.test(Sepal.Length)
```

Por tanto, nuestro p valor es igual a ***0.02***, con lo que podríamos concluir que nuestros datos NO siguen una distribución normal

- ***Prueba de Hegazy-Green***

La prueba de Hegazy-Green para la normalidad se basa en el siguiente estadístico:

<center>
![](https://i.ibb.co/3M97BnQ/Hegazy-Green.jpg){width=200}
</center><br>

```{r}
## Paquete "normtest"

## nrepl: considera el número de replicas en simulación de Monte Carlo
hegazy1.norm.test(Sepal.Length, nrepl = 20000) 
```

Con este tipo de test nuestro p valor es menor a 0.05, con lo que podríamos concluir que nuestros datos NO siguen una distribución normal

- ***Prueba de Jarque-Bera Ajustada***

La prueba de Jarque–Bera Ajustada para la normalidad se basa en el siguiente estadístico:

<center>
![](https://i.ibb.co/LNs2hNm/Jarque-Bera-Ajustada.jpg){width=200}
</center><br>

> Utiliza un estadístico en la prueba que involucra la curtosis y la asimetría. – Usada por economistas.

```{r}
## Paquete "normtest"

jb.norm.test(Sepal.Length, nrepl = 2000)
```
El resultado para el p valor es igual mayor a 0.05, por lo que podríamos concluir que nuestros datos siguen una distribución normal

- ***Prueba de Kurtosis***

La prueba de Kurtosis para la normalidad se basa en el siguiente estadístico:

<center>
![](https://i.ibb.co/bd9tZTJ/Kurtosis.jpg){width=200}
</center><br>

```{r}
## Paquete "normtest"

kurtosis.norm.test(Sepal.Length, nrepl = 2000)
```
Así, nuestro p valor es igual a ***0.1045***, con lo que podríamos concluir que nuestros datos siguen una distribución normal

- ***Prueba de Skewness***

La prueba de Skewness para la normalidad se basa en el siguiente estadístico:

<center>
![](https://i.ibb.co/QPn2VMh/Skewness.jpg){width=200}
</center><br>

```{r}
## Paquete "normtest"

skewness.norm.test(Sepal.Length, nrepl = 2000)
```
Así, nuestro p valor es igual mayor a 0.05, con lo que podríamos concluir que nuestros datos siguen una distribución normal

- ***Prueba de Spiegelhalter***

La prueba de Spiegelhalter para la normalidad se basa en el siguiente estadístico:

<center>
![](https://i.ibb.co/NTMtwRK/Spiegelhalter.jpg){width=200}
</center><br>

```{r}
## Paquete "normtest"

spiegelhalter.norm.test(Sepal.Length, nrepl=2000)
```
Nuestro p valor es mayor a 0.05, con lo que podríamos concluir que nuestros datos siguen una distribución normal

- ***Prueba de Weisberg-Bingham***

La prueba de Weisberg-Bingham para la normalidad se basa en el siguiente estadístico:

<center>
![](https://i.ibb.co/d5ZgJCv/Weisberg-Bingham.jpg){width=200}
</center><br>

```{r}
## Paquete "normtest"

wb.norm.test(Sepal.Length, nrepl=2000)
```
Nuestro resultado para el p valor es mayor a  0.05, con lo que podríamos concluir que nuestros datos NO siguen una distribución normal

- ***Prueba de Agostino***

La prueba de Agostino sirve para medir el nivel de asimetría de una normal en los datos. Bajo la hipótesis de la normalidad, los datos deben ser simétricos (es decir, la asimetría debe ser igual a cero).

```{r}
## Paquete "moment"
library(moments)

agostino.test(Sepal.Length)
```
Así, nuestro p valor es igual a ***0.1104***, con lo que podríamos concluir que nuestros datos siguen una distribución normal

- ***Prueba de Shapiro-Wilk***

La prueba de Shapiro-Wilk es ampliamente recomendada para la prueba de normalidad y proporciona una mejor potencia que K-S. Se basa en la correlación entre los datos y las puntuaciones normales correspondientes.

La prueba de normalidad es sensible al tamaño de muestra. Las muestras pequeñas con mayor frecuencia pasan las pruebas de normalidad. Por lo tanto, es importante combinar la inspección visual y la prueba de significación de normalidad para tomar la decisión correcta.

> Es más poderosa cuando se compara con otras pruebas de normalidad cuando la muestra es pequeña.

```{r}
shapiro.test(Sepal.Length)
```

Así, nuestro p valor es igual a ***0.01018***, con lo que podríamos concluir que nuestros datos NO siguen una distribución normal

- ***Resumen normalidad***

Visto los diferentes resultados de las pruebas realizadas para evidenciar normalidad, podemos inferir que los resultados dependerán en gran medida del tipo de test que elijamos usar. Y la pregunta del millón sería ¿entonces cuál debo utilizar? Pues no podemos darte una única respuesta, todo va a depender de tus datos, de la pregunta de investigación que quieras responder y la teoría detrás de cada análisis, porque es a partir de ello que tomaremos la mejor desición sobre que tipo de prueba es la más adecuada. 

<center>
![](https://i.ibb.co/vYdnczW/loco.gif){width=350}
</center><br>
 
Sin embargo, la ***Prueba de Shapiro-Wilk*** es uno de los test más confiables y robustos, por lo que según sus resultados, nuestros datos NO se ajustarían a una distribución normal, por lo que hasta este momento, tendrémos que usar las pruebas para datos no paramétricos

# Homocesdasticidad 
<a name="5"></a>

La homocedasticidad en un modelo estadístico predictivo ocurre si en todos los grupos de datos de una o más observaciones, la varianza del modelo respecto de las variables explicativas (o independientes) se mantiene constante. Así, un modelo de regresión puede ser homocedástico o no, en cuyo caso se habla de heterocedasticidad. Una varianza constante nos permite disponer de modelos más fiables, además, si una varianza, aparte de ser constante es también más pequeña, nos dará como resultado una predicción del modelo más fiable.

> La heterocedasticidad es, en estadística, cuando los errores no son constantes a lo largo de toda la muestra. El término es contrario a homocedasticidad.

<center>
![](https://i.ibb.co/89CcvLL/img.jpg){width=350}
</center><br>

En realidad es muy común observar que en un modelo de regresión aparezca la heterocedasticidad, ya que es complicado encontrar la variables perfectas desde el principio del experimento. Estos son algunos motivos que pueden producir heterocedasticidad

Contrastar la homocedasticidad de nuestros datos es en muchos test estadísticos una condición necesaria para poder ejecutarlos. Existen test para contrastar la homocedasticidad específicos para dos grupos (test F de Fisher) o para más de dos (test de Bartlett). Sin embargo, el test de Levene permite contrastar la homocedasticidad independientemente del número de grupos presentes. Es decir, lo puede ejecutar sobre dos o más de dos.

Existen diferentes test que permiten evaluar la distribución de la varianza. Todos ellos consideran como hipótesis nula que la varianza es igual entre los grupos y como hipótesis alternativa que no lo es. La diferencia entre ellos es el estadístico de centralidad que utilizan:

- Los test que trabajan con la media de la varianza son los más potentes cuando las poblaciones que se comparan se distribuyen de forma normal.

- Utilizar la media truncada mejora el test cuando los datos siguen una distribución de Cauchy (colas grandes).

- La mediana consigue mejorarlo cuando los datos siguen una distribución asimétrica.

Por lo general, si no se puede alcanzar cierta seguridad de que las poblaciones que se comparan son de tipo normal, es recomendable recurrir a test que comparen la mediana de la varianza. 

A continuación veremos algunos test para profundizar un poco más en el tema

<center>
![](https://i.ibb.co/SyDpFpv/computer.gif){width=350}
</center><br>

- ***F-test***

También conocido como contraste de la razón de varianzas, contrasta la hipótesis nula de que dos poblaciones normales tienen la misma varianza. Es muy potente, detecta diferencias muy sutiles, pero es muy sensible a violaciones de la normalidad de las poblaciones. Por esta razón, no es un test recomendable si no se tiene mucha certeza de que las poblaciones se distribuyen de forma normal.

Hagamos un ejercicio, esta vez lo haremos con la confiable base de datos <res>iris</res>. Para ello, vamos a cargar los paquetes necesarios

```{r message=FALSE}
library(ggplot2)
library(dplyr)

## Cargamos la base de datos "iris" 
data("iris")

## Filtramos los datos que utilizaremos
iris2 <- filter(iris, Species %in% c("versicolor", "virginica"))

dim(iris2)
head(iris2)
```

Ahora calculemos la varianza de la longitud del pétalo (Petal.Length) de las dos especies de plantas, _I. versicolor_ e _I. virginica_)

```{r}
aggregate(Petal.Length~Species, data = iris2, FUN = var)
```

Ahora si hagamos la prueba

```{r}
var.test(x = iris2[iris2$Species == "versicolor", "Petal.Length"],
         y = iris2[iris2$Species == "virginica", "Petal.Length"] )
```

Así, de acuerdo al resultado anterior, *p-value = 0.2637*, podemos concluir que no se encuentra diferencias significativas entre las varianzas de los dos grupos, osea, tenemos un comportamiento de las varianzas en homocedasticidad.

- ***Test de Levene***

El test de Levene se puede aplicar con la función <res>leveneTest()</res> del paquete <res>car</res>. Se caracteriza, además de por poder comparar 2 o más poblaciones, por permitir elegir entre diferentes estadísticos de centralidad: mediana (por defecto), media, media truncada. Esto es importante a la hora de contrastar la homocedasticidad dependiendo de si los grupos se distribuyen de forma normal o no.

```{r}
library(car)

leveneTest(y = iris2$Petal.Length, group = iris2$Species, center = "median")
```

Así, de acuerdo al resultado anterior *0.3041*, podemos concluir que no se encuentra diferencias significativas entre las varianzas de los dos grupos, osea, tenemos un comportamiento de las varianzas en homocedasticidad.

- ***Test de Bartlett***

Permite contrastar la igualdad de varianza en 2 o más poblaciones sin necesidad de que el tamaño de los grupos sea el mismo. Es más sensible que el ***_Test de Levene_*** a la falta de normalidad, pero si se está seguro de que los datos provienen de una distribución normal, es la mejor opción.

```{r}
## Organizamos los datos para realizar el test
a <- iris[iris$Species == "versicolor", "Petal.Length"]
b <- iris[iris$Species == "virginica", "Petal.Length"]

## Aplicamos el test
bartlett.test(list(a,b))
```

Así, de acuerdo al resultado anterior, ***p-value = 0.2637***, podemos concluir que no se encuentra diferencias significativas entre las varianzas de los dos grupos, osea, tenemos un comportamiento de las varianzas en homocedasticidad.

Ahora, si se aplica a los 3 grupos a la vez, sí hay evidencias de que la varianza no es la misma en todos ellos. Idea que se puede intuir a partir de sus gráficas (Fig. 5).

```{r out.width="100%"}
ggplot(iris, aes(x = Species, y = Petal.Length)) + 
  geom_boxplot(color = "black", fill = "steelblue")+
  geom_jitter(alpha = 0.5)+
  scale_y_continuous("Longitud del pétalo", 
                     limits = c(0, 8),
                     breaks = seq(0, 8, by = 2))+
  scale_x_discrete("Iris")+
  theme(axis.title.y = element_text(size = 18),
        axis.title.x = element_text(size = 18, face = "italic"),
        axis.text.y = element_text(size = 16),
        axis.text.x = element_text(size = 16, face = "italic"))+
  theme(panel.border = element_blank(), 
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(), 
        axis.line = element_line(colour = "black", size = 1),
        panel.background = element_blank())
```

Fig. 5. Comportamiento de datos de la Longitud del pétalo para tres especies de plantas del género _Iris_.

Ahora organizamos nuestro datos para poder seguir con el ejercicio 

```{r}
## Calculamos la varianza respecto a las variables
aggregate(Petal.Length ~ Species, data = iris, FUN = var)

## Y aplicamos el test
bartlett.test(iris$Sepal.Length ~ iris$Species)
```

Así, de acuerdo al resultado anterior, ***p-value = 0.0003345***, podemos concluir que si se encuentran diferencias significativas entre las varianzas de los tres grupos, osea, tenemos un comportamiento de las varianzas en heterocedasticidad.

- ***Test de Brown-Forsythe***

La prueba de Brown-Forsythe (B-F) se utiliza para probar el supuesto de varianzas iguales en ANOVA. Se puede encontrar dentro del paquete <res>onewaytests</res>, y se realiza con la función <res>hov()</res>. Este test es equivalente al ***Test de Levene*** cuando se emplea la mediana como medida de centralidad.

```{r}
library(onewaytests)

iris %>%
  group_by(Species) %>%
  summarize(Variance = var(Petal.Length))

bf.test(Petal.Length ~ Species, data = iris)
```

En nuestro ejemplo, se rechaza la hipótesis nula, por lo que podemos concluir que si se encuentran diferencias significativas entre las varianzas de los tres grupos, osea, tenemos un comportamiento de las varianzas en heterocedasticidad. 

- ***Resumen Homocesdasticidad***

Si tenemos la seguridad de que nuestras muestras siguen una distribución normal, son recomendables el ***F-test*** y el test de ***Bartlet***, pareciendo ser el segundo más recomendable ya que el primero es muy potente pero extremadamente sensible a desviaciones de la normal. 

Si no se tiene la seguridad de que las poblaciones de origen son normales, se recomiendan el ***Test de Leven*** utilizando la mediana.

# Conclusión 
<a name="6"></a>

Como pudimos leer y aprender, debemos hacer pruebas a nuestros datos para saber que tipo de pruebas podríamos aplicar a futuro, dependiendo si son datos paramétricos o no paramétricos. En la cual la normalidad y la homocesdasticidad de los datos, jugarán un papel importante, en la decisión personal a partir de los resultados de las pruebas de que tipo de datos tenemos.

Recuerda que las diferentes pruebas tienen un mismo objetivo, pero todas manejan ciertos critrios que dependerán de nuestros datos, nuestras preguntas de investigación y lo que en nuestro proceso de aprendizaje, podamos afirmar si es o no la prueba adecuada para nuestro estudio. 

<center>
![](https://i.ibb.co/fds6BC7/dancing.gif){width=350}
</center><br>

Así que los invitamos a seguir leyendo mucho más, recuerden que la intención de estos post no es más si no dar pequeñas pinceladas del amplio mundo de R en la biología. 

No siendo más, muchas gracias por leernos y esperemos realmente, que de una u otra forma podamos contribuir al conocimiento de la ciencia.

<center>
![](https://i.ibb.co/1dBjTMs/mine.gif){width=350}
</center><br>

# Literatura citada 
<a name="7"></a>

- [Cómo aplicar las pruebas paramétricas bivariadas t de Student y ANOVA en SPSS. Caso práctico](https://redined.mecd.gob.es/xmlui/bitstream/handle/11162/15044/00720123000097.pdf?sequence=1&isAllowed=y)

- [Pruebas paramétricas: definición y características](https://lamenteesmaravillosa.com/pruebas-parametricas-definicion-y-caracteristicas/)

- [Understanding Q-Q Plots](https://data.library.virginia.edu/understanding-q-q-plots/)

- [QQ-plots: Quantile-Quantile plots - R Base Graphs](http://www.sthda.com/english/wiki/qq-plots-quantile-quantile-plots-r-base-graphs)

- [Pruebas de Normalidad](https://rpubs.com/dvillasanao/Pruebas_de_Normalidad)

- [Pruebas de Normalidad](https://rpubs.com/MSiguenas/122473)

- [Pruebas de Normalidad](https://rpubs.com/luisxsuper/normalidad_test)

- [Homocedasticidad: qué es, importancia y ejemplos](https://www.lifeder.com/homocedasticidad/) 

- [Heterocedasticidad](https://economipedia.com/definiciones/heterocedasticidad.html)

- [Test de Levene Homocedasticidad](https://vivaelsoftwarelibre.com/test-de-levene-homocedasticidad/)

- [Análisis de la homogeneidad de varianza (homocedasticidad)](https://www.cienciadedatos.net/documentos/9_homogeneidad_de_varianza_homocedasticidad.html)

# Más información
<a name="8"></a>

Estos análisis se han realizado utilizando el software R (v.4.1.0) y Rstudio (v. 1.4.1717)

Recuerda que todos nuestros códigos están almacenados en [GitHub](https://github.com/RBiologos/Posts) 

<center>
![](https://i.ibb.co/DpKmR1k/github.png){width="350"}
</center>